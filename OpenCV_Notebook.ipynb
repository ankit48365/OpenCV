{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/swlh/opencv-from-import-to-face-detection-machine-learning-in-python-426a7fb05016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this, only needed one time\n",
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:\\MyGit\\OpenCV\\input_images\\m_d.jpg\")\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the color scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: From now, the image is referred to as rgb_img .\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to display images quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewImage(img, name_of_window):\n",
    "    cv2.namedWindow(name_of_window, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name_of_window, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping an Image:\n",
    "\n",
    "To crop an image, we can directly provide width and height similar to slicing in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax for cropping <image_name>[y:y+h, x:x+w]\n",
    "crop = rgb_img[250:800, 200:1500]\n",
    "viewImage(crop, \"Cropped Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing an Image:\n",
    "\n",
    "For image scaling, we can use the cv2.resize() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below commands can be used to give width and height of an image !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1230"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1855"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the % times of the original image you want to scale\n",
    "scaling = 50\n",
    "#Change Width and Height\n",
    "width = int(rgb_img.shape[1] * scaling / 100)\n",
    "height = int(rgb_img.shape[0] * scaling / 100)\n",
    "dim = (width,height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main command, that takes the new width and height stored in dim, and then use it in resize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(img,dim,interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run below to see the resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewImage(resized, \"Resized Image by 50%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to verify, run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotating an Image:\n",
    "Images can be rotated clockwise and counterclockwise by applying a +ve or-ve angle rotation to it respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, w, d) = rgb_img.shape\n",
    "center_img = (w//2, h//2)\n",
    "rotationMatrix = cv2.getRotationMatrix2D(center_img, 180, 1.0)\n",
    "rotated = cv2.warpAffine(rgb_img, rotationMatrix, (w, h))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view the rotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewImage(rotated, \"Rotated Image 180 degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below sections left\n",
    "\n",
    "# Grayscaling and Thresholding an Image:\n",
    "Grayscale is a black and white, single-channeled version of an Image. Whereas, Thresholding will turn all dark shades (less than 127 value) to 0 and all the bright shades to 255.\n",
    "gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2GRAY)\n",
    "ret, threshold_img = cv2.threshold(gray_img,127,255,0)\n",
    "viewImage(gray_img, \"Grayscale Image\")\n",
    "viewImage(threshold_img, \"Threshold Image\")\n",
    "\n",
    "# Blurring/Smoothing an Image:\n",
    "There are multiple functions in OpenCV that can be used to control the Blurring and Smoothing of an Image. For the purpose of this blog, we will be using the Gaussian Blur function.\n",
    "The Gaussian Blur function takes 3 parameters:\n",
    "Image you want to Blur.\n",
    "A tuple of 2 positive odd numbers. When increased, the blur effect increases.\n",
    "The sigmaX and sigmaY for the Gaussian Kernel. When set as 0, they’re automatically calculated from kernel size.\n",
    "Gaussian Blur is highly effective in removing noise from an image.\n",
    "blurred = cv2.GaussianBlur(rgb_img, (61,61), 0)\n",
    "viewImage(blurred, \"Blurred Image\")\n",
    "\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html\n",
    "\n",
    "\n",
    "# Drawing a Bounding Box on an Image:\n",
    "A bounding box is nothing but a rectangle or a square around an object. This creation is extensively used by many face detecting or object detecting applications.\n",
    "\n",
    "output = rgb_img.copy()\n",
    "cv2.rectangle(output, (2600,800), (4100, 2400), (0, 255, 255), 10)\n",
    "viewImage(output, \"Rectangle on an Image\")\n",
    "\n",
    "Parameters of cv2.rectangle() are:\n",
    "1. Image import.\n",
    "2. x1,y1 — Top Left Corner.\n",
    "3. x2,y2 — Bottom Right Corner.\n",
    "4. Rectangle Color — Depends on the Image imported. (In our case RGB).\n",
    "5. Thickness of the production.\n",
    "Similarly, we can draw lines using cv2.line and add text using cv2.putText on an Image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection:\n",
    "Face detection can be done by using inbuilt face_cascade and detectMultiScale function in OpenCV. We also make use of the CascadeClassifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D:\\MyGit\\OpenCV\\input_images\\m_d.jpg\"\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haar feature-based cascade classifier can be read in the paper “Rapid Object Detection using a Boosted Cascade of Simple Features” by Paul Viola and Michael Jones.\n",
    "https://web.iitd.ac.in/~sumeet/viola-cvpr-01.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detectMultiScale function uses four parameters:\n",
    "1. Grayscale Image Input.\n",
    "2. scaleFactor compensates for the fact that some faces may be close or far away from the camera.\n",
    "3. The detection algorithm uses a moving window to detect objects.minNeighbors defines how many objects are detected near the current one before it declares the face found.\n",
    "4. minSize gives the size of each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d7cd0e856885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaleFactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminNeighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mface_detected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Face detected!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_detected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.1, minNeighbors = 5, minSize = (10,10))\n",
    "face_detected = format(len(faces)) + \"Face detected!\"\n",
    "print(face_detected)\n",
    "for(x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255,255,0), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if Face Detect Works !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_detected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8ccef766d865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mviewImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_detected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'face_detected' is not defined"
     ]
    }
   ],
   "source": [
    "viewImage(image, face_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
